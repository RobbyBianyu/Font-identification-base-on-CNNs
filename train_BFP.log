number_epochs = 50, len(results) >= total_chunks, without augment, double activations, BFP16, 3 conve
Step 2: Defining utility functions...
Step 3: Processing folder and extracting image chunks...
Step 4: Mapping string labels to integers...
After remapping, label range: 0 170585  Number of classes: 170586
Paths & labels prepared: 10227270 images, 170586 classes
Step 5: Subsampling classes for quick experiment...
Subsampled dataset: 59940 images, 1000 classes
Step 6: Defining transforms and dataset...
Dataset initialized: 59940 samples
Step 7: Splitting dataset...
Split into train/val/test: 47952/5994/5994
Step 8: Checking CUDA...
Using device: cuda
Step 9: Initializing model class... 
Step 10: Setting up loss criterion... 
Step 11: Starting hyper-parameter search...
Testing lr=0.01, batch_size=16
→ val_acc = 0.8654

Testing lr=0.01, batch_size=32
→ val_acc = 0.8832

Testing lr=0.01, batch_size=64
→ val_acc = 0.8822

Testing lr=0.01, batch_size=128
→ val_acc = 0.8842

Testing lr=0.001, batch_size=16
→ val_acc = 0.8775

Testing lr=0.001, batch_size=32
→ val_acc = 0.8755

Testing lr=0.001, batch_size=64
→ val_acc = 0.8340

Testing lr=0.001, batch_size=128
→ val_acc = 0.7651

Testing lr=0.0001, batch_size=16
→ val_acc = 0.7404

Testing lr=0.0001, batch_size=32
→ val_acc = 0.5742

Testing lr=0.0001, batch_size=64
→ val_acc = 0.2316

Testing lr=0.0001, batch_size=128
/root/CNN.py:394: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load('best_model.pth'))
→ val_acc = 0.0257

Best validation accuracy: 0.8842
Best config: learning_rate=0.01, batch_size=128
Step 12: evaluating on test set...
Test accuracy = 0.8815
